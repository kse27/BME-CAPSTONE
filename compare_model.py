# -*- coding: utf-8 -*-
"""BME Capstone

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c1vqEGlqlw-oNHchHQOYDC3zXh1Z6Gmw

"""

"""#  시계열 정보를 반영하지 않고 예측

## XGBoost
"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb

xgboost_dict = {}
mse_xg_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # XGBoost 모델 학습
        xgboost = xgb.XGBRegressor()
        xgboost.fit(X_train, y_train)
        xgboost_pred = xgboost.predict(X_test)

        # 모델 저장
        xgboost_dict[label]=xgboost

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, xgboost_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_xg_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor

rf_dict = {}
mse_rf_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id','updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # RandomForest 모델 학습
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(X_train, y_train)
        rf_pred = rf.predict(X_test)

        # 모델 저장
        rf_dict[label]= rf

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, rf_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_rf_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## SVR"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR

svr_dict={}
mse_svr_dict={}

target = ['updrs_1','updrs_2','updrs_3','updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id','updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # SVR 모델 학습
        svr_rbf = SVR(kernel='rbf', C=100, gamma=0.5, epsilon=.1)
        svr_rbf.fit(X_train, y_train)
        svr_pred=svr_rbf.predict(X_test)

        # 모델 저장
        svr_dict[label]=svr_rbf

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, svr_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_svr_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## XGB+RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb

# xgboost_dict = {}
# rf_dict = {}
m_dict={}
mse_1_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # XGBoost 모델 학습
        xgboost_pred=xgboost_dict[label].predict(X_test)

        # RandomForest 모델 학습
        rf_pred=rf_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (xgboost_pred + rf_pred) / 2

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_1_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## XGB+SVR"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
import xgboost as xgb

# xgboost_dict = {}
# svr_dict = {}
mse_2_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # XGBoost 모델 학습
        xgboost_pred=xgboost_dict[label].predict(X_test)

        # SVR 모델 학습
        svr_pred=svr_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (xgboost_pred + svr_pred) / 2

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_2_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## SVR+RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
import xgboost as xgb

# rf_dict = {}
# svr_dict = {}
mse_3_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # RandomForest 모델 학습
        rf_pred=rf_dict[label].predict(X_test)

        # SVR 모델 학습
        svr_pred=svr_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (rf_pred + svr_pred) / 2

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_3_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## XGB+SVR+RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
import xgboost as xgb

# xgboost_dict = {}
# rf_dict = {}
# svr_dict = {}
mse_4_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # # XGBoost 모델 학습
        # xgboost = xgb.XGBRegressor()
        # xgboost.fit(X_train, y_train)
        # xgboost_pred = xgboost.predict(X_test)
        xgboost_pred=xgboost_dict[label].predict(X_test)

        # # RandomForest 모델 학습
        # rf = RandomForestRegressor(n_estimators=100, random_state=42)
        # rf.fit(X_train, y_train)
        # rf_pred = rf.predict(X_test)
        rf_pred=rf_dict[label].predict(X_test)

        # # SVR 모델 학습
        # svr_rbf = SVR(kernel='rbf', C=100, gamma=0.5, epsilon=.1)
        # svr_rbf.fit(X_train, y_train)
        # svr_pred = svr_rbf.predict(X_test)
        svr_pred=svr_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (xgboost_pred+rf_pred + svr_pred) / 3

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_4_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)


# MSE 계산
predicted_values = np.concatenate(predictions)
mse = np.mean(np.square(np.array(true_values) - predicted_values))
print("Mean Squared Error:", mse)
