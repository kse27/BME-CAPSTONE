# -*- coding: utf-8 -*-
"""BME Capstone

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c1vqEGlqlw-oNHchHQOYDC3zXh1Z6Gmw

# 🧸 BME Capstone
:predicting MDS-UPDR scores by using protein and peptide levels

👉 202100805 김시은, 202102238 유희진

# 데이터 전처리
"""

import csv
from collections import defaultdict
import pandas as pd

#Load a dataset into a Pandas DataFrame
train_proteins = pd.read_csv("/content/drive/MyDrive/BME/amp-parkinsons-disease-progression-prediction/train_proteins.csv")
train_peptides = pd.read_csv("/content/drive/MyDrive/BME/amp-parkinsons-disease-progression-prediction/train_peptides.csv")
train_clinical = pd.read_csv("/content/drive/MyDrive/BME/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv")

#Uniprot, peptide 종류 수 확인

unique_Uniprot = train_proteins['UniProt'].nunique()
print("Unique values in 'Uniprot' column:", unique_Uniprot)

unique_peptide=train_peptides['Peptide'].nunique()
print("Unique valeus in 'Peptide' column:", unique_peptide)

# Function to prepare dataset with all the steps mentioned above:
def prepare_dataset(train_proteins, train_peptides):
    # Step 1: Grouping
    df_protein_grouped = train_proteins.groupby(['visit_id','UniProt'])['NPX'].mean().reset_index()
    df_peptide_grouped = train_peptides.groupby(['visit_id','Peptide'])['PeptideAbundance'].mean().reset_index()

    # Step 2: Pivoting
    df_protein = df_protein_grouped.pivot(index='visit_id',columns = 'UniProt', values = 'NPX').rename_axis(columns=None).reset_index()
    df_peptide = df_peptide_grouped.pivot(index='visit_id',columns = 'Peptide', values = 'PeptideAbundance').rename_axis(columns=None).reset_index()

    # Step 3: Merging
    pro_pep_df = df_protein.merge(df_peptide, on = ['visit_id'], how = 'left')

    return pro_pep_df

pro_pep_df = prepare_dataset(train_proteins, train_peptides)
# CSV 파일로 저장
pro_pep_df.to_csv('/content/drive/MyDrive/BME/a_data.csv', index=False)
print(pro_pep_df.head())

import pandas as pd
a_data = pd.read_csv("/content/drive/MyDrive/BME/a_data.csv")
train_clinical = pd.read_csv("/content/drive/MyDrive/BME/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv")

# visit_id를 기준으로 두 파일 병합 (외부 조인)
merged_df = pd.merge(a_data, train_clinical, on='visit_id', how='outer')

# 마지막 열을 제거 - 약물 복용 여부
df = merged_df.drop(merged_df.columns[-1], axis=1)

# 'patient id'와 'visitmonth' 열을 제거합니다
df = df.drop(['patient_id', 'visit_month'], axis=1)

# 'visit_id' 열을 '_'로 분할하여 'patient_id'와 'visit_month'로 나누기
df[['patient_id', 'visit_month']] = df['visit_id'].str.split('_', expand=True)

# 'patient_id'와 'visit_month' 열의 데이터 타입을 적절히 변환 (옵션)
df['patient_id'] = df['patient_id'].astype(int)
df['visit_month'] = df['visit_month'].astype(int)

# 열 순서 조정하여 맨 뒤에 있는 두 개의 열을 맨 앞으로 가져오기
columns = df.columns.tolist()
new_order = columns[-2:] + columns[:-2]

# 새로운 순서로 데이터프레임 생성
df = df[new_order]

# patient_id를 기준으로 오름차순으로 정렬한 후, visit_month를 기준으로 오름차순으로 정렬합니다
df_sorted = df.sort_values(by=['patient_id', 'visit_month'])

df_sorted

# CSV 파일로 저장합니다

from sklearn.impute import SimpleImputer

# 각 환자의 각 열에 대한 존재하는 값들의 평균을 계산합니다
patient_means = df_sorted.groupby('patient_id').mean()

# null 값을 해당 환자의 평균 값으로 대체합니다
imputer = SimpleImputer(strategy='mean')

feature_list = df_sorted.columns[3:-4]

# null 값만 대체합니다
for col in feature_list:
    mask = df_sorted[col].isnull()  # null 값을 확인합니다
    if mask.any():  # null 값을 포함하는 경우에만 처리합니다
        for patient_id, mean_value in patient_means[col].items():
            df_sorted.loc[(df_sorted['patient_id'] == patient_id) & mask, col] = mean_value  # 해당 환자의 null 값만 대체합니다

df_sorted

#null을 평균값으로 대체하고도 남아있는 null값은 0으로 대체
for col in feature_list:# 특정 열에 있는 null 값을 0으로 대체 (예를 들어, 'protein1' 열)
  df_sorted[col].fillna(0, inplace=True)

# 결과 확인
print(df_sorted.isnull().sum())

df_sorted.to_csv('/content/drive/MyDrive/BME/modified_data2.csv', index=False)

"""#  시계열 정보를 반영하지 않고 예측

## XGBoost
"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb

xgboost_dict = {}
mse_3_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # XGBoost 모델 학습
        xgboost = xgb.XGBRegressor()
        xgboost.fit(X_train, y_train)
        xgboost_pred = xgboost.predict(X_test)

        # 모델 저장
        xgboost_dict[label]=xgboost

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, xgboost_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_3_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

import matplotlib.pyplot as plt
import seaborn as sns

for label,model in xgboost_dict.items():

# 특징 중요도 확인
  feature_importance = model.feature_importances_

# 특징 중요도를 DataFrame으로 변환
  feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})

# 중요도 기준으로 내림차순 정렬
  feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# 중요도가 높은 순으로 상위 10개 특징 선택
  top_features = feature_importance_df.head(50)

# 상위 10개 특징 시각화
  plt.figure(figsize=(10, 6))
  sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')
  plt.title(f'Top 10 Features by Importance {label}')
  plt.xlabel('Importance')
  plt.ylabel('Feature')
  plt.show()

"""## RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor

rf_dict = {}
mse_rf_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id','updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # RandomForest 모델 학습
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(X_train, y_train)
        rf_pred = rf.predict(X_test)

        # 모델 저장
        rf_dict[label]= rf

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, rf_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_rf_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## SVR"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR

svr_dict={}
mse_svr_dict={}

target = ['updrs_1','updrs_2','updrs_3','updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id','updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # SVR 모델 학습
        svr_rbf = SVR(kernel='rbf', C=100, gamma=0.5, epsilon=.1)
        svr_rbf.fit(X_train, y_train)
        svr_pred=svr_rbf.predict(X_test)

        # 모델 저장
        svr_dict[label]=svr_rbf

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, svr_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_3_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## XGB+RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb

# xgboost_dict = {}
# rf_dict = {}
m_dict={}
mse_3_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # # XGBoost 모델 학습
        # xgboost = xgb.XGBRegressor()
        # xgboost.fit(X_train, y_train)
        # xgboost_pred = xgboost.predict(X_test)
        xgboost_pred=xgboost_dict[label].predict(X_test)

        # # RandomForest 모델 학습
        # rf = RandomForestRegressor(n_estimators=100, random_state=42)
        # rf.fit(X_train, y_train)
        # rf_pred = rf.predict(X_test)
        rf_pred=rf_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (xgboost_pred + rf_pred) / 2

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_3_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## XGB+SVR"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
import xgboost as xgb

# xgboost_dict = {}
# svr_dict = {}
mse_3_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # # XGBoost 모델 학습
        # xgboost = xgb.XGBRegressor()
        # xgboost.fit(X_train, y_train)
        # xgboost_pred = xgboost.predict(X_test)
        xgboost_pred=xgboost_dict[label].predict(X_test)

        # # SVR 모델 학습
        # svr_rbf = SVR(kernel='rbf', C=100, gamma=0.5, epsilon=.1)
        # svr_rbf.fit(X_train, y_train)
        # svr_pred = svr_rbf.predict(X_test)
        svr_pred=svr_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (xgboost_pred + svr_pred) / 2

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_3_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## SVR+RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
import xgboost as xgb

# rf_dict = {}
# svr_dict = {}
mse_3_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # # RandomForest 모델 학습
        # rf = RandomForestRegressor(n_estimators=100, random_state=42)
        # rf.fit(X_train, y_train)
        # rf_pred = rf.predict(X_test)
        rf_pred=rf_dict[label].predict(X_test)

        # # SVR 모델 학습
        # svr_rbf = SVR(kernel='rbf', C=100, gamma=0.5, epsilon=.1)
        # svr_rbf.fit(X_train, y_train)
        # svr_pred = svr_rbf.predict(X_test)
        svr_pred=svr_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (rf_pred + svr_pred) / 2

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_3_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""## XGB+SVR+RF"""

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
import xgboost as xgb

# xgboost_dict = {}
# rf_dict = {}
# svr_dict = {}
mse_3_dict = {}

target = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']

# KFold 객체 생성
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for label in target:
    data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
    data = data.dropna(subset=[label])

    # 종속 변수 및 독립 변수 분리
    X = data.drop(['visit_id','visit_month','patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)
    y = data[label]

    # 각 fold에 대해 모델 학습 및 평가
    mse_list = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # # XGBoost 모델 학습
        # xgboost = xgb.XGBRegressor()
        # xgboost.fit(X_train, y_train)
        # xgboost_pred = xgboost.predict(X_test)
        xgboost_pred=xgboost_dict[label].predict(X_test)

        # # RandomForest 모델 학습
        # rf = RandomForestRegressor(n_estimators=100, random_state=42)
        # rf.fit(X_train, y_train)
        # rf_pred = rf.predict(X_test)
        rf_pred=rf_dict[label].predict(X_test)

        # # SVR 모델 학습
        # svr_rbf = SVR(kernel='rbf', C=100, gamma=0.5, epsilon=.1)
        # svr_rbf.fit(X_train, y_train)
        # svr_pred = svr_rbf.predict(X_test)
        svr_pred=svr_dict[label].predict(X_test)

        # 앙상블을 위한 예측값 결합
        y_pred = (xgboost_pred+rf_pred + svr_pred) / 3

        # 평가: MSE 계산
        mse = mean_squared_error(y_test, y_pred)
        mse_list.append(mse)

    # 평균 MSE 계산
    avg_mse = sum(mse_list) / len(mse_list)
    mse_3_dict[label] = avg_mse
    print("Mean Squared Error for", label, ":", avg_mse)

"""# 시계열 정보를 반영하여 예측"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# 데이터 불러오기
data = pd.read_csv("/content/drive/MyDrive/BME/modified_data2.csv")  # 데이터 파일 경로에 맞게 수정해주세요.

from sklearn.model_selection import train_test_split

# 각 환자의 고유한 patient_id 확인
unique_patients = data['patient_id'].unique()

# 각 환자를 train 및 test 세트로 분할
train_patients, test_patients = train_test_split(unique_patients, test_size=0.2, random_state=42)

# train 및 test 세트에 속하는 인덱스 추출
train_idx = data['patient_id'].isin(train_patients)
test_idx = data['patient_id'].isin(test_patients)


# train 및 test 데이터 분할
train_data = data[train_idx]
test_data = data[test_idx]

#print(train_data,test_data)

train_data.isnull().any()

"""## UPDRS1"""

import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.optimizers import Adam
import pandas as pd

# 각 환자의 데이터를 따로 처리하여 시계열 형태로 만들기
train_patient_sequences = []
test_patient_sequences = []

# 'updrs_1'을 포함한 데이터셋에서 필요한 피처만 선택
features = ['FIYGGC(UniMod_4)GGNR', 'P36980', 'NVVYTC(UniMod_4)NEGYSLIGNPVAR', 'AGLAASLAGPHSIVGR', 'KYLYEIAR',
            'FNKPFVFLM(UniMod_35)IEQNTK', 'Q9NYU2', 'LLELTGPK', 'C(UniMod_4)FSGQC(UniMod_4)ISK', 'GLGEISAASEFK',
            'VVEESELAR', 'P00748', 'GKRPYQEGTPC(UniMod_4)SQC(UniMod_4)PSGYHC(UniMod_4)K', 'LVYPSC(UniMod_4)EEK',
            'LEEQAQQIR', 'DALSSVQESQVAQQAR', 'LEPGQQEEYYR', 'TATSEYQTFFNPR', 'HYTNPSQDVTVPC(UniMod_4)PVPPPPPC(UniMod_4)C(UniMod_4)HPR',
            'VGGVQSLGGTGALR', 'LGPLVEQGR', 'C(UniMod_4)MC(UniMod_4)PAENPGC(UniMod_4)R', 'SGIEC(UniMod_4)QLWR',
            'GC(UniMod_4)PTEEGC(UniMod_4)GER', 'M(UniMod_35)ADEAGSEADHEGTHSTKR', 'SIVVSPILIPENQR', 'MKYWGVASFLQK',
            'FFLC(UniMod_4)QVAGDAK', 'P06310', 'GNSYFMVEVK', 'GATLALTQVTPQDER', 'EILSVDC(UniMod_4)STNNPSQAK',
            'P17174', 'NILDRQDPPSVVVTSHQAPGEK', 'GLSAEPGWQAK', 'LLPAQLPAEKEVGPPLPQEAVPLQK', 'KTLLSNLEEAKK',
            'ADSGEGDFLAEGGGVR', 'FTILDSQGK', 'C(UniMod_4)LVEKGDVAFVKHQTVPQNTGGK', 'SC(UniMod_4)VGETTESTQC(UniMod_4)EDEELEHLR',
            'LETPDFQLFK', 'ILGPLSYSK', 'P20774', 'KVESELIKPINPR', 'GAAPPKQEFLDIEDP', 'P16070', 'SVPMVPPGIK',
            'DKETC(UniMod_4)FAEEGKK', 'P27169', 'updrs_1']

# train_data = pd.read_csv('/content/drive/MyDrive/BME/modified_data2.csv')
# test_data = pd.read_csv('/path/to/test_data.csv')  # 테스트 데이터 경로 설정

train_patients = train_data['patient_id'].unique()
test_patients = test_data['patient_id'].unique()

for patient_id in train_patients:
    patient_data = train_data[train_data['patient_id'] == patient_id][features].values
    train_patient_sequences.append(patient_data)

for patient_id in test_patients:
    patient_data = test_data[test_data['patient_id'] == patient_id][features].values
    test_patient_sequences.append(patient_data)

# 모델 정의
model = Sequential()
model.add(LSTM(units=50, input_shape=(None, len(features) - 1), return_sequences=True))  # 각 시퀀스의 길이를 None으로 설정
model.add(Dropout(0.2))  # 드롭아웃 레이어를 추가하여 과적합을 방지합니다.
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# Adam optimizer를 사용하여 모델을 컴파일하고, 학습률을 조정합니다.
adam = Adam(learning_rate=0.001)  # 원하는 학습률로 설정합니다.
model.compile(optimizer=adam, loss='mean_squared_error')

# 모델 훈련
for sequence in train_patient_sequences:
    X_train = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_train = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_train).any():
        continue

    X_train = np.expand_dims(X_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_train = np.expand_dims(y_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    model.fit(X_train, y_train, epochs=50, batch_size=16)

# 모델 예측
predictions = []
true_values = []

for sequence in test_patient_sequences:
    X_test = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_test = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_test).any():
        continue

    X_test = np.expand_dims(X_test, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_pred = model.predict(X_test)
    predictions.append(y_pred.flatten())

    # 현재 시퀀스의 마지막 실제값이 NaN이 아니면 true_values에 추가합니다.
    last_value = sequence[-1][-1]
    if not np.isnan(last_value):
        true_values.append(last_value)

# MSE 계산
predicted_values = np.concatenate(predictions)
mse = np.mean(np.square(np.array(true_values) - predicted_values))
print("Mean Squared Error:", mse)

"""## UPDRS2"""

import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.optimizers import Adam
import pandas as pd

# 각 환자의 데이터를 따로 처리하여 시계열 형태로 만들기
train_patient_sequences = []
test_patient_sequences = []

# 'updrs_2'을 포함한 데이터셋에서 필요한 피처만 선택
features =['FIYGGC(UniMod_4)GGNR', 'LQDLYSIVR', 'MKYWGVASFLQK', 'P30086', 'C(UniMod_4)LPVTAPENGK', 'ETYGEMADC(UniMod_4)C(UniMod_4)AK', 'LEPGQQEEYYR', 'GLSAEPGWQAK', 'KYFIDFVAR',
           'M(UniMod_35)YLGYEYVTAIR', 'EQLSLLDRFTEDAKR', 'GAQTQTEEEMTR', 'P07998', 'NPDSSTTGPWC(UniMod_4)YTTDPTVR', 'SC(UniMod_4)VGETTESTQC(UniMod_4)EDEELEHLR',
           'SC(UniMod_4)DKTHTC(UniMod_4)PPC(UniMod_4)PAPELLGGPSVFLFPPKPK', 'LVNEVTEFAK', 'LSKELQAAQAR', 'P19827', 'ALANSLAC(UniMod_4)QGK', 'TSAHGNVAEGETKPDPDVTER',
           'HYEGSTVPEK', 'VKDISEVVTPR', 'Q9NYU2', 'THLGEALAPLSK', 'P01591', 'EDC(UniMod_4)NELPPRR', 'AGC(UniMod_4)VAESTAVC(UniMod_4)R', 'AGLAASLAGPHSIVGR', 'P07333',
           'EHVAHLLFLR', 'P01034', 'QVVAGLNFR', 'KVESELIKPINPR', 'KTLLSNLEEAK', 'P36980', 'HYTNPSQDVTVPC(UniMod_4)PVPPPPPC(UniMod_4)C(UniMod_4)HPR', 'GWVTDGFSSLK',
           'VLLDGVQNPR', 'HLDSVLQQLQTEVYR', 'QRQEELC(UniMod_4)LAR', 'IGDQWDKQHDMGHMMR', 'YGLVTYATYPK', 'VDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSK', 'NFPPSQDASGDLYTTSSQLTLPATQC(UniMod_4)LAGK',
           'SSGLVSNAPGVQIR', 'LTASAPGYLAITK', 'KQINDYVEKGTQGK', 'ADSGEGDFLAEGGGVR', 'TLKIENVSYQDKGNYR','updrs_2']

train_patients = train_data['patient_id'].unique()
test_patients = test_data['patient_id'].unique()

for patient_id in train_patients:
    patient_data = train_data[train_data['patient_id'] == patient_id][features].values
    train_patient_sequences.append(patient_data)

for patient_id in test_patients:
    patient_data = test_data[test_data['patient_id'] == patient_id][features].values
    test_patient_sequences.append(patient_data)

# 모델 정의
model = Sequential()
model.add(LSTM(units=50, input_shape=(None, len(features) - 1), return_sequences=True))  # 각 시퀀스의 길이를 None으로 설정
model.add(Dropout(0.2))  # 드롭아웃 레이어를 추가하여 과적합을 방지합니다.
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# Adam optimizer를 사용하여 모델을 컴파일하고, 학습률을 조정합니다.
adam = Adam(learning_rate=0.001)  # 원하는 학습률로 설정합니다.
model.compile(optimizer=adam, loss='mean_squared_error')

# 모델 훈련
for sequence in train_patient_sequences:
    X_train = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_train = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_train).any():
        continue

    X_train = np.expand_dims(X_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_train = np.expand_dims(y_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    model.fit(X_train, y_train, epochs=50, batch_size=16)

# 모델 예측
predictions = []
true_values = []

for sequence in test_patient_sequences:
    X_test = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_test = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_test).any():
        continue

    X_test = np.expand_dims(X_test, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_pred = model.predict(X_test)
    predictions.append(y_pred.flatten())

    # 현재 시퀀스의 마지막 실제값이 NaN이 아니면 true_values에 추가합니다.
    last_value = sequence[-1][-1]
    if not np.isnan(last_value):
        true_values.append(last_value)

# MSE 계산
predicted_values = np.concatenate(predictions)
mse = np.mean(np.square(np.array(true_values) - predicted_values))
print("Mean Squared Error:", mse)

"""## UPDRS3"""

import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.optimizers import Adam
import pandas as pd

# 각 환자의 데이터를 따로 처리하여 시계열 형태로 만들기
train_patient_sequences = []
test_patient_sequences = []

# 'updrs_3'을 포함한 데이터셋에서 필요한 피처만 선택
features = ['TPC(UniMod_4)TVSC(UniMod_4)NIPVVSGKEC(UniMod_4)EEIIR', 'QHVVYGPWNLPQSSYSHLTR', 'FIYGGC(UniMod_4)GGNR', 'LLEVPEGR', 'P13521', 'GLPAPIEK',
            'ETYGEMADC(UniMod_4)C(UniMod_4)AK', 'Q6UXD5', 'KLGQSLDC(UniMod_4)NAEVYVVPWEK', 'SDVMYTDWKK', 'LADGGATNQGRVEIFYR', 'MYLGYEYVTAIR',
            'LSYTC(UniMod_4)EGGFR', 'KLVGYLDR', 'VTSIQDWVQK', 'QTHQPPAPNSLIR', 'FM(UniMod_35)ETVAEK', 'KDSGFQM(UniMod_35)NQLR', 'P10643', 'YANC(UniMod_4)HLAR',
            'M(UniMod_35)YLGYEYVTAIR', 'HYEGSTVPEK', 'P25311', 'P08123', 'KMTVTDQVNC(UniMod_4)PK', 'NPDSSTTGPWC(UniMod_4)YTTDPTVR', 'GYPGVQAPEDLEWER',
            'NFPPSQDASGDLYTTSSQLTLPATQC(UniMod_4)LAGK', 'GSPAINVAVHVFR', 'C(UniMod_4)PNPPVQENFDVNKYLGR', 'P01877', 'P04406', 'EGDMLTLFDGDGPSAR', 'VFQEPLFYEAPR',
            'RLGMFNIQHC(UniMod_4)K', 'QFTSSTSYNR', 'EKLQDEDLGFL', 'THLGEALAPLSK', 'YQC(UniMod_4)YC(UniMod_4)YGR', 'DPTFIPAPIQAK', 'VTEIWQEVMQR', 'SDVMYTDWK',
            'IEIPSSVQQVPTIIK', 'YPSLSIHGIEGAFDEPGTK', 'THPHFVIPYR', 'IASFSQNC(UniMod_4)DIYPGKDFVQPPTK', 'RLEGQEEEEDNRDSSMK', 'Q13332', 'TLKIENVSYQDKGNYR', 'C(UniMod_4)FSGQC(UniMod_4)ISK','updrs_3']


train_patients = train_data['patient_id'].unique()
test_patients = test_data['patient_id'].unique()

for patient_id in train_patients:
    patient_data = train_data[train_data['patient_id'] == patient_id][features].values
    train_patient_sequences.append(patient_data)

for patient_id in test_patients:
    patient_data = test_data[test_data['patient_id'] == patient_id][features].values
    test_patient_sequences.append(patient_data)

# 모델 정의
model = Sequential()
model.add(LSTM(units=50, input_shape=(None, len(features) - 1), return_sequences=True))  # 각 시퀀스의 길이를 None으로 설정
model.add(Dropout(0.2))  # 드롭아웃 레이어를 추가하여 과적합을 방지합니다.
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# Adam optimizer를 사용하여 모델을 컴파일하고, 학습률을 조정합니다.
adam = Adam(learning_rate=0.001)  # 원하는 학습률로 설정합니다.
model.compile(optimizer=adam, loss='mean_squared_error')

# 모델 훈련
for sequence in train_patient_sequences:
    X_train = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_train = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_train).any():
        continue

    X_train = np.expand_dims(X_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_train = np.expand_dims(y_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    model.fit(X_train, y_train, epochs=50, batch_size=16)

# 모델 예측
predictions = []
true_values = []

for sequence in test_patient_sequences:
    X_test = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_test = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_test).any():
        continue

    X_test = np.expand_dims(X_test, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_pred = model.predict(X_test)
    predictions.append(y_pred.flatten())

    # 현재 시퀀스의 마지막 실제값이 NaN이 아니면 true_values에 추가합니다.
    last_value = sequence[-1][-1]
    if not np.isnan(last_value):
        true_values.append(last_value)

# MSE 계산
predicted_values = np.concatenate(predictions)
mse = np.mean(np.square(np.array(true_values) - predicted_values))
print("Mean Squared Error:", mse)

"""## UPDRS4"""

import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.optimizers import Adam
import pandas as pd

# 각 환자의 데이터를 따로 처리하여 시계열 형태로 만들기
train_patient_sequences = []
test_patient_sequences = []

# 'updrs_4'을 포함한 데이터셋에서 필요한 피처만 선택
features = ['VNHVTLSQPK', 'SILENLR', 'STGGISVPGPMGPSGPR', 'M(UniMod_35)LTPEHVFIHPGWK', 'DVLLEAC(UniMod_4)C(UniMod_4)ADGHR', 'AQC(UniMod_4)GGGLLGVR',
            'SVPPSASHVAPTETFTYEWTVPK', 'VC(UniMod_4)PFAGILENGAVR', 'HGNVAEGETKPDPDVTER', 'EHVAHLLFLR', 'KLSSWVLLMK', 'LEPGQQEEYYR', 'EKLQDEDLGFL',
            'C(UniMod_4)PFPSRPDNGFVNYPAKPTLYYK', 'LLDNWDSVTSTFSK', 'Q92520', 'TPSAAYLWVGTGASEAEK', 'PPTSAHGNVAEGETKPDPDVTER', 'WSRPQAPITGYR', 'Q99435',
            'SFQTGLFTAAR', 'MMAVAADTLQR', 'SVPMVPPGIK', 'AADDTWEPFASGK', 'P23083', 'Q99683', 'FIYGGC(UniMod_4)GGNR', 'QFTSSTSYNR', 'AYLEEEC(UniMod_4)PATLRK',
            'FVVTDGGITR', 'VPFDAATLHTSTAMAAQHGMDDDGTGQK', 'GC(UniMod_4)PTEEGC(UniMod_4)GER', 'QKVEPLRAELQEGAR', 'RTHLPEVFLSK', 'Q92876', 'AIGAVPLIQGEYMIPC(UniMod_4)EK',
            'VYC(UniMod_4)DMNTENGGWTVIQNR', 'TSAHGNVAEGETKPDPDVTER', 'AGLAASLAGPHSIVGR', 'AGAAAGGPGVSGVC(UniMod_4)VC(UniMod_4)K', 'RLEAGDHPVELLAR', 'EDC(UniMod_4)NELPPRR',
            'GSPSGEVSHPR', 'C(UniMod_4)LAPLEGAR', 'VTGVVLFR', 'GNSYFMVEVK', 'LDEVKEQVAEVR', 'ATEDEGSEQKIPEATNR', 'SVIPSDGPSVAC(UniMod_4)VK', 'C(UniMod_4)VC(UniMod_4)PVSNAMC(UniMod_4)R','updrs_4']


train_patients = train_data['patient_id'].unique()
test_patients = test_data['patient_id'].unique()

for patient_id in train_patients:
    patient_data = train_data[train_data['patient_id'] == patient_id][features].values
    train_patient_sequences.append(patient_data)

for patient_id in test_patients:
    patient_data = test_data[test_data['patient_id'] == patient_id][features].values
    test_patient_sequences.append(patient_data)

# 모델 정의
model = Sequential()
model.add(LSTM(units=50, input_shape=(None, len(features) - 1), return_sequences=True))
model.add(Dropout(0.2))  # 드롭아웃 레이어를 추가하여 과적합을 방지합니다.
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

adam = Adam(learning_rate=0.001)
model.compile(optimizer=adam, loss='mean_squared_error')

# 모델 훈련
for sequence in train_patient_sequences:
    X_train = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_train = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_train).any():
        continue

    X_train = np.expand_dims(X_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_train = np.expand_dims(y_train, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    model.fit(X_train, y_train, epochs=50, batch_size=16)

# 모델 예측
predictions = []
true_values = []

for sequence in test_patient_sequences:
    X_test = sequence[:-1, :-1]  # t일 때의 데이터를 입력으로 사용
    y_test = sequence[1:, -1]  # t+1일 때의 updrs 점수를 타겟으로 사용

    # null 값을 가진 행을 스킵합니다.
    if np.isnan(y_test).any():
        continue

    X_test = np.expand_dims(X_test, axis=0)  # LSTM 모델 입력을 위해 차원 확장
    y_pred = model.predict(X_test)
    predictions.append(y_pred.flatten())

    # 현재 시퀀스의 마지막 실제값이 NaN이 아니면 true_values에 추가합니다.
    last_value = sequence[-1][-1]
    if not np.isnan(last_value):
        true_values.append(last_value)

# MSE 계산
predicted_values = np.concatenate(predictions)
mse = np.mean(np.square(np.array(true_values) - predicted_values))
print("Mean Squared Error:", mse)
